1.对于类$G_i$,总体的分布为$N(\mu_i,\sigma_i^2)$,其中$i=1,2.$可以通过计算马氏距离进行判别，
不妨设$\mu_1>\mu_2$,按距离判别准则有

$$\begin{cases}&x\in G_1,&x>\mu^*,\\&x\in G_2,&x\leqslant\mu^*,\end{cases}$$

其中$\mu^*=\frac{\sigma_1\mu_2+\sigma_2\mu_1}{\sigma_1+\sigma_2}.$试求错判概率 Pr(2|1)和 Pr(1|2).

首先给出马氏距离定义：

$$
d(x)=\frac{(x-\mu)^{2}}{\sigma^{2}}
$$

将两个总体带入后易得到分界点：$\mu^*=\frac{\sigma_1\mu_2+\sigma_2\mu_1}{\sigma_1+\sigma_2}.$

Pr(2|1)=P{$x\in G_{2}|x\in G_{1}$} 

根据距离判别准则有：

$$
\begin{aligned}
Pr(2|1)&=P_{X_{1}}\{X\leq \mu^{*}\}\\
&=P\{\frac{X-\mu_{1}}{\sigma_{1}}\leq \frac{\mu_{2}-\mu_{1}}{\sigma_1+\sigma_{2}}\}\\
&=1-\phi(\frac{\mu_{1}-\mu_{2}}{\sigma_1+\sigma_{2}})
\end{aligned}
$$

对于$Pr(1|2)$同理

2.设三个总体$\pi_1,\pi_2$和$\pi_3$的分布分别为：$N(2,0.5^2),N(0,2^2)$和$N(3,1^2).$采用下面两
种判别准则，试问样品 $x=2.5$ 应判归为哪一类？
(1) 按距离判别准则；
(2)按 Bayes 判别准则，取先验概率为$q_1=q_2=q_3=1/3$,且考虑损失，当$i\neq j$时，损失
为$C(j|i)=1$,否则损失为$C(j|i)=0.$

(1)按照马氏距离准则判别：将$x=2.5$带入马氏距离中

$$
d(x)=\frac{(x-\mu)^{2}}{\sigma^{2}}
$$
$$
\begin{aligned}
&\pi_{1}:d_{1}(2.5)=1\\
&\pi_{1}:d_{2}(2.5)=1.5625\\
&\pi_{1}:d_{3}(2.5)=0.25\\
\end{aligned}
$$

因此按距离判别准则，归为$\pi_{3}$ 

(2)贝叶斯判别准则：

$$
C(j|i)q_{i}f_{i}
$$

由于惩罚项和贝叶斯先验概率一致，因此至于比较密度函数大小即可
$$
\begin{aligned}
f_{1}(2.5)=\frac{1}{\sqrt{2\pi}*0.5}exp\{-\frac{1}{2}d_{1}\}\\
f_{2}(2.5)=\frac{1}{\sqrt{2\pi}*2}exp\{-\frac{1}{2}d_{2}\}\\
f_{3}(2.5)=\frac{1}{\sqrt{2\pi}*1}exp\{-\frac{1}{2}d_{3}\}\\
\end{aligned}
$$

比较后可得$f_{1}(2.5)$最大，因此按照贝叶斯判别准则，应该归类为$\pi_{1}$

3.设总体$\pi_i$的均值为$\boldsymbol\mu_i(i=1,2)$,具有相同的协方差矩阵为$\boldsymbol\Sigma$,令$\overline{\mu}=\frac12(\boldsymbol{a}^{\prime}\boldsymbol{\mu}_1+\boldsymbol{a}^{\prime}\boldsymbol{\mu}_2)$,
其中$a=\boldsymbol{\Sigma}^{-1}(\boldsymbol{\mu}_1-\boldsymbol{\mu}_2).$试证明：
(1) $E( \boldsymbol{a}^{\prime }\boldsymbol{X}| \pi _1) > \overline {\mu };$
(2) $E( \boldsymbol{a}^{\prime }\boldsymbol{X}| \pi _{2}) < \overline {\mu }.$

(1)要证明

$$
\begin{aligned}
&a^{\prime}\mu_{1}>\frac{1}{2}a^{\prime}(\mu_{1}+\mu_{2})\\
&\frac{1}{2}a^{\prime}(\mu_{1}-\mu_2)>0\\
&\frac{1}{2}(\mu_{1}-\mu_2)^{\prime}\Sigma^{-1}(\mu_{1}-\mu_2)>0\\
&由\Sigma为正定矩阵可知不等号成立
\end{aligned}
$$

(2)与(1)同理

4.设有两个二元正态总体$\pi_1\sim N_2(\boldsymbol{\mu}_1,\boldsymbol{\Sigma}_1)$和$\pi_2\sim N_2(\boldsymbol{\mu}_2,\boldsymbol{\Sigma}_2)$,其中

$$\mu_1=\left(\begin{array}{c}10\\15\end{array}\right),\:\boldsymbol{\Sigma}_1=\left(\begin{array}{cc}18&12\\12&32\end{array}\right),\:\boldsymbol{\mu}_2=\left(\begin{array}{cc}20\\25\end{array}\right),\:\boldsymbol{\Sigma}_2=\left(\begin{array}{cc}20&-7\\-7&5\end{array}\right).$$


假设先验概率$q_1=q_2$,且损失为$C(2|1)=10$和$C(1|2)=75.$
试问样本$x_1=(20,20)^{\prime}$和$x_2=(15,20)^{\prime}$ 各应判归为哪一类？

(1) 按 Fisher 判别准则；
(2)按 Bayes 判别准则，其中假设$\Sigma_2=\Sigma_1=\left(\begin{array}{cc}18&12\\12&32\end{array}\right);$
(3)已知样品$x=(20,20)^\prime$,对$i=1,2$,试计算后验概率 Pr$(\pi_i|x).$


(1)Fisher判别准则：
现在想要寻找某个方向$a$ ,使得不同组数据投影之后，在该方向上的中心拉的足够开。即使得两者
的距离达到最大

$$\frac{||a\bar{X}_1-a\bar{X}_2||}{\sqrt{a\left(\Sigma_1+\Sigma_2\right)a^{\prime}}}$$
考虑总体被分为 2 类，投影方向应该使得下面这个距离达到最大

$$\hat{a}=\arg\max_a\frac{a^{\prime}\left(\mu_1-\mu_2\right)\left(\mu_1-\mu_2\right)^{\prime}a}{a^{\prime}\left(\Sigma_1+\Sigma_2\right)a}$$
由题5的不等式可知，此时$a$取$(\Sigma_{1}+\Sigma_{2})^{-1} (\mu_{1}-\mu_{2})$
计算可得：
$$
a=
$$

(2)按Bayes判别准则：
$$
\begin{aligned}
R_{1}=\{x:x^{\prime}\Sigma^{-1}(\mu_{1}-\mu_2)-\frac12(\mu_1+\mu_2)\Sigma^{-1}(\mu_1-\mu_2)>lnk\}\\
R_{2}=\{x:x^{\prime}\Sigma^{-1}(\mu_{1}-\mu_2)-\frac12(\mu_1+\mu_2)\Sigma^{-1}(\mu_1-\mu_2)<lnk\}
\end{aligned}
$$
由于惩罚项权重不同，因此取$k=\frac{q_2C(1|2)}{q_{1}C(1|2)}$ 即可

(3)
$$
Pr(\pi_{i}|x)=q_{i}f_{i}(x)/\sum(q_if_i(x))
$$
在本题中，由于先验概率相同，只需要看两个整体中的密度比即可
$$
Pr(\pi_{i}|x)=f_{i}(x)/\sum(f_i(x))
$$
其中密度函数
$$
f_i(x)=\frac{1}{\sqrt{2\pi}|\Sigma_{i}^{1/2}|}exp\{-\frac{1}{2}(x-\mu_{i})^{\prime}\Sigma^{-1}_{i}(x-\mu_i)\}
$$


5.已知$x_i^{(k)}$为来自类$G_k$的简单随机样本，其中$k=1,2;i=1,\cdots,n_k$.
记$d=$ $\overline{x}^{(1)}-\overline{x}^{(2)}$,其中$\overline{x}^{(k)}=\frac1{n_k}\sum_{i=1}^{n_k}\boldsymbol{x}_i^{(k)}.$
令$\mathbf{S}=\frac1{n_1+n_2-2}(\mathbf{V}_1+\mathbf{V}_2)$,其中$\mathbf{V}_k$为类$G_k$的样本离差阵.试证明：
$a=\mathbf{S}^{-1}(\overline{x}^{(1)}-\overline{x}^{(2)})$使比值$(a^{\prime}d)^2/a^{\prime}\mathbf{S}a$达最大值，
且最大值为马氏距离$D^2=(\overline{x}^{(1)}-\overline{x}^{(2)})^{\prime}\mathbf{S}^{-1}(\overline{x}^{(1)}-\overline{x}^{(2)}).$

易知，若$a=\mathbf{S}^{-1}(\overline{x}^{(1)}-\overline{x}^{(2)})$使比值$(a^{\prime}d)^2/a^{\prime}\mathbf{S}a$达最大值，则带入后即为马氏距离
首先证明一个不等式：
$$(b^{\prime}d)^{2}\leq (b^{\prime}Bb)\left(d^{\prime}B^{-1}d\right)$$
其中$b,d$为$p$维向量$B$为一个$p*p$的正定矩阵
$$b'd=b'B^{1/2}B^{-1/2}d=\left(B^{1/2}b\right)'\left(B^{-1/2}d\right)$$
则可由Cauchy-Shwarz不等式可知（向量点乘平方小于模的平方相乘）
$$(\left(B^{1/2}b\right)'\left(B^{-1/2}d\right))^{2}\leq(b^{\prime}Bb)\left(d^{\prime}B^{-1}d\right)$$
等号当且仅当$\left(B^{1/2}b\right)'=\lambda\left(B^{-1/2}d\right)$  即向量共线成比例的时候成立
在本题中，取$a=b,d=d,B=S$ 
$$
(a^{\prime}d)^{2}\leq (a^{\prime}Sa)\left(d^{\prime}S^{-1}d\right)
$$
则可知$(a^{\prime}d)^2/a^{\prime}\mathbf{S}a\leq(d^{\prime}S^{-1}d)=D^{2}$  得证
且等号成立条件为$\left(S^{1/2}a\right)'=\lambda\left(S^{-1/2}d\right)$ ,取$\lambda=1$将$S^{-1/2}$乘过去则可得到
$$
a=\mathbf{S}^{-1}(\overline{x}^{(1)}-\overline{x}^{(2)})
$$
6.试证明：
$$-\frac{1}{2}(x-\mu_{1})^{\prime}\Sigma^{-1}(x-\mu_{1})+\frac{1}{2}(x-\mu_{2})^{\prime}\Sigma^{-1}(x-\mu_{2})\\=(\boldsymbol{\mu}_{1}-\boldsymbol{\mu}_{2})^{\prime}\boldsymbol{\Sigma}^{-1}\boldsymbol{x}-\frac{1}{2}(\boldsymbol{\mu}_{1}-\boldsymbol{\mu}_{2})^{\prime}\boldsymbol{\Sigma}^{-1}(\boldsymbol{\mu}_{1}+\boldsymbol{\mu}_{2}).$$
直接将原式展开证明即可：
注意$x^{\prime}\Sigma^{-1}\mu=\mu^{\prime}\Sigma^{-1}x$即可

7.考虑下面两个数据集：

$$\left.\mathbf{X}_1=\left(\begin{array}{cc}3&7\\2&4\\4&7\end{array}\right.\right),\quad\mathbf{X}_2=\left(\begin{array}{cc}6&9\\5&7\\4&8\end{array}\right).$$

计算可得：

$$\overline{\boldsymbol{x}}_1=\left(\begin{array}{c}3\\6\end{array}\right),\quad\overline{\boldsymbol{x}}_2=\left(\begin{array}{c}5\\8\end{array}\right),\quad\mathbf{S}_{\mathrm{pooled}}=\left(\begin{array}{cc}1&1\\1&2\end{array}\right).$$



(1)计算由式(11.16)定义的线性判别函数；
(2)如果假设先验概率和损失相等，对给定的观测值$x_0=(2,7)^{\prime}$,试用 Fisher 线性判别准则(11.17)把$x_0$归类为总体$\pi_1$或$\pi_2.$ 

$S_{pooled}$的求法可由题5得
(1)
$$
W(x)=(\boldsymbol{\mu}_{1}-\boldsymbol{\mu}_{2})^{\prime}\boldsymbol{\Sigma}^{-1}\boldsymbol{x}-\frac{1}{2}(\boldsymbol{\mu}_{1}-\boldsymbol{\mu}_{2})^{\prime}\boldsymbol{\Sigma}^{-1}(\boldsymbol{\mu}_{1}+\boldsymbol{\mu}_{2})
$$
带入得数后可得：
$$
W(x)=(-2,0)x+8=-2x_{1}+8
$$

(2)  
$$
W(x_{0})=4>0
$$
故归类为总体$\pi_{1}$


8.在两个$p$元正态总体$N_p(\boldsymbol{\mu}_k,\boldsymbol{\Sigma})(k=1,2)$下，设$\boldsymbol\mu_1,\boldsymbol{\mu}_2$和$\boldsymbol{\Sigma}$均为已知.又设线性判

别函数为：

$$W(\boldsymbol{X})=(\boldsymbol{X}-\boldsymbol{\overline{\mu}})'\boldsymbol{\Sigma}^{-1}(\boldsymbol{\mu}_{1}-\boldsymbol{\mu}_{2}),\quad\overline{\boldsymbol{\mu}}=\frac{1}{2}(\boldsymbol{\mu}_{1}+\boldsymbol{\mu}_{2}).$$

判别准则为：

$$\left.\left\{\begin{array}{ll}\text{判}\boldsymbol{X}\in G_1,&W(\boldsymbol{X})>0,\\\text{判}\boldsymbol{X}\in G_2,&W(\boldsymbol{X})\leqslant0.\end{array}\right.\right.$$

试求错判概率$\Pr(2|1)$和$\Pr(1|2)$.

易知$\Pr(2|1)$和$\Pr(1|2)$相等，这里只讨论$\Pr(2|1)$,由正态分布性质，若$X\in \pi_{1}$
$$
W(X)\sim N(\frac{1}{2}(\mu_{1}-\mu_{2})^{\prime}\Sigma^{-1}(\mu_{1}-\mu_{2}),(\mu_{1}-\mu_{2})^{\prime}\Sigma^{-1}(\mu_{1}-\mu_{2})) 
$$
则可知
$$
\begin{aligned}
&P\{W(x)>0\}\\
&=P\{\frac{W(x)-\frac{1}{2}(\mu_{1}-\mu_{2})^{\prime}\Sigma^{-1}(\mu_{1}-\mu_{2})}{(\mu_{1}-\mu_{2})^{\prime}\Sigma^{-1}(\mu_{1}-\mu_{2})}>-\frac{1}{2}\}\\
&=1-\phi(\frac{1}{2})=0.31
\end{aligned}
$$

9.考虑线性函数：$Y=\xi^{\prime}X$.如果$X$来自总体$\pi _1$,则 令 $E( \boldsymbol{X}) = \boldsymbol{\mu }_1$, Cov$(\boldsymbol{X})=\boldsymbol{\Sigma};$如果$X$来自总体$\pi_2$,则令$E(\boldsymbol X)=\boldsymbol\mu_2$, Cov$(\boldsymbol X)=\boldsymbol\Sigma$.令$m=\frac12(\mu_{1Y}+\mu_{2Y})=\frac12(\boldsymbol\xi^{\prime}\boldsymbol{\mu}_{1}+\boldsymbol\xi^{\prime}\boldsymbol{\mu}_{2}).$ 给定$\xi^\prime=(\boldsymbol{\mu}_1-\boldsymbol{\mu}_2)^{\prime}\boldsymbol{\Sigma}^{-1}$,试证明：
(1) $E( \boldsymbol{\xi }^{\prime }\boldsymbol{X}| \pi _1) - m= \boldsymbol{\xi }^{\prime }\boldsymbol{\mu }_1- m> 0;$ 
(2) $E( \boldsymbol{\xi }^{\prime }\boldsymbol{X}| \pi _{2}) - m= \boldsymbol{\xi }^{\prime }\boldsymbol{\mu }_{2}- m< 0.$

直接带入即可：
$$
\begin{aligned}
E( \boldsymbol{\xi }^{\prime }\boldsymbol{X}| \pi _1) - m= \boldsymbol{\xi }^{\prime }\boldsymbol{\mu }_1- m\\
=\frac{1}{2}(\mu_{1}-\mu_{2})^{\prime}\Sigma^{-1}(\mu_{1}-\mu_{2})
\end{aligned}
$$
由于$\Sigma$为正定矩阵，则可知原式严格大于零。
（2）同理可得

10.令两个总体的密度函数分别为

$$f_1(x)=\left\{\begin{array}{ll}1-|x|,&|x|\leqslant1,\\0,&\text{其他},\end{array}\right.\quad f_2(x)=\left\{\begin{array}{ll}1-|x-0.5|,&-0.5\leqslant x\leqslant1.5,\\0,&\text{其他}.\end{array}\right.$$

(1)绘制 $f_1(x)$ 和 $f_2(x)$ 的密度函数；
(2)当$q_1=q_2$且$C(2|1)=C(1|2)$时，试给出判别准则，并确定判别区域$R_1$和$R_2;$ 
(3)当$q_1=0.2$且$C(2|1)=C(1|2)$时，试给出判别准则，并确定判别区域$R_1$和$R_2.$

(1)
```R
# 定义函数
f1 <- function(x) {
  ifelse(abs(x) <= 1, 1 - abs(x), 0)
}

f2 <- function(x) {
  ifelse(-0.5 <= x & x <= 1.5, 1 - abs(x - 0.5), 0)
}

# 创建x值的向量
x <- seq(-1, 1, length.out = 1000)
y <- seq(-0.5,1.5,length.out=1000)
# 计算函数值
y1 <- f1(x)
y2 <- f2(y)

# 绘制函数
plot(x, y1, type = "l", col = "blue", lwd = 2, xlim=c(-1,1.5),ylim = c(0, 1), xlab = "x", ylab = "Density", main = "Density Functions")
lines(y, y2, type = "l", col = "red", lwd = 2)

# 添加图例
legend("topright", legend = c("f1(x)", "f2(x)"), col = c("blue", "red"), lty = 1, lwd = 2)
```
![[密度图.png]]
（2）(3)直接考虑第三问即可，第二问为一个退化情况
 $$
 \begin{aligned}
 ECM(R_{1},R_{2})&=C(2|1)Pr(2|1,R)q_{1}+C(1|2)Pr(1|2,R)q_{2}\\
 &=\int_{R_{2}} C(2|1)q_{1}f_{1}+\int_{R_{1}} C(1|2)q_{2}f_2dx\\
 &=\int_{R_{2}} (C(2|1)q_{1}f_{1}-C(1|2)q_{2}f_2)dx+C(1|2)q_{2}
 \end{aligned}
$$
由于后一项为常数项，因此只需要考虑让前面积分值尽可能的小，也就是只积分负的部分则：

$$
\begin{aligned}
R_{1}=\{x:[C(2|1)q_{1}f_{1}(x)\geq[C(1|2)q_{2}f_{2}(x)\}\\
R_{2}=\{x:[C(2|1)q_{1}f_{1}(x)<[C(1|2)q_{2}f_{2}(x)\}
\end{aligned}
$$


11.已知两个总体的分布为$N_p(\boldsymbol{\mu}_k,\boldsymbol{\Sigma})(k=1,2).$又设$\boldsymbol\mu_1,\boldsymbol{\mu}_2$和$\boldsymbol{\Sigma}$均为已知，先验概率为$q_1$和$q_2$,且满足$q_1+q_2=1$,错判损失为$C(1|2)$和$C(2|1).$试写出 Bayes 判别准则和距离判别准则，并说明它们之间的关系.

距离判别：
$$\left.\left\{\begin{array}{ll}X\in G_1,&d^2\left(X,G_1\right)<d^2\left(X,G_2\right)\\X\in G_2,&d^2\left(X,G_1\right)\geq d^2\left(X,G_2\right)\end{array}\right.\right.$$

$$
\begin{aligned}
d^2(X,G_1) - d^2(X,G_2) 
&= (X - \mu_1)'\Sigma^{-1}(X - \mu_1) - (X - \mu_2)'\Sigma^{-1}(X - \mu_2) \\
&= (X - \mu_1)'\Sigma^{-1}[(X - \mu_1) - (X - \mu_2)] + (X - \mu_1)'\Sigma^{-1}(X - \mu_2) - (X - \mu_2)'\Sigma^{-1}(X - \mu_2) \\
&= (X - \mu_1)'\Sigma^{-1}(\mu_2 - \mu_1) + (X - \mu_2)'\Sigma^{-1}(X - \mu_1) - (X - \mu_2)'\Sigma^{-1}(X - \mu_2) \\
&= (X - \mu_1)'\Sigma^{-1}(\mu_2 - \mu_1) + (X - \mu_2)'\Sigma^{-1}(\mu_2 - \mu_1) \\
&= 2(X - \frac{\mu_1 + \mu_2}{2})'\Sigma^{-1}(\mu_2 - \mu_1) \\
&= 2(\mu_2 - \mu_1)'\Sigma^{-1}(X - \frac{\mu_1 + \mu_2}{2})
\end{aligned}
$$


Bayes判别准则
判别函数：
$$
W(x)=(\boldsymbol{\mu}_{1}-\boldsymbol{\mu}_{2})^{\prime}\boldsymbol{\Sigma}^{-1}\boldsymbol{x}-\frac{1}{2}(\boldsymbol{\mu}_{1}-\boldsymbol{\mu}_{2})^{\prime}\boldsymbol{\Sigma}^{-1}(\boldsymbol{\mu}_{1}+\boldsymbol{\mu}_{2})=(\mu_2 - \mu_1)'\Sigma^{-1}(X - \frac{\mu_1 + \mu_2}{2})
$$
由于区域是与$lnk=C(1|2)q_2/C(2|1)q_1$进行比较，因此当该比例为1即$lnk=0$时距离判别与Bayes判别等价，这也说明Bayes判别在先验信息不足时退化为距离判别